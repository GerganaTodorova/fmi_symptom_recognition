{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import spacy\n",
    "import stanza\n",
    "from spacy_stanza import StanzaLanguage\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Span\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 20:47:21 INFO: Loading these models for language: bg (Bulgarian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | btb     |\n",
      "| pos       | btb     |\n",
      "| lemma     | btb     |\n",
      "| depparse  | btb     |\n",
      "=======================\n",
      "\n",
      "2020-11-30 20:47:21 INFO: Use device: gpu\n",
      "2020-11-30 20:47:21 INFO: Loading: tokenize\n",
      "2020-11-30 20:47:26 INFO: Loading: pos\n",
      "2020-11-30 20:47:27 INFO: Loading: lemma\n",
      "2020-11-30 20:47:27 INFO: Loading: depparse\n",
      "2020-11-30 20:47:28 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# LOAD ENTITY RULER\n",
    "\n",
    "snlp = stanza.Pipeline(lang=\"bg\")\n",
    "nlp = StanzaLanguage(snlp)\n",
    "ruler = EntityRuler(nlp)\n",
    "ruler.from_disk(\"entity_ruler\")  \n",
    "nlp.add_pipe(ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for display options - describes color options for visualizing the named entities\n",
    "def getDisplayOptions():\n",
    "\n",
    "    entities = [\"ORGAN\", \"ANATOMICAL_SYSTEM\", \"SYMPTOM\", \"COMPLAINT\", \"FAMILY\", \"RISK_FACTOR\", \"NEGATION\", \"FAMILY_HISTORY_SYNONYM\", \"NO_COMPLAINT\", \"NO_SYMPTOM\", \"FAMILY_HISTORY\", \"NO_RISK_FACTOR\"]\n",
    "    \n",
    "    colors = {\"ORGAN\":\"#F9E79F\", \"ANATOMICAL_SYSTEM\":\"#6fcbf7\", \"SYMPTOM\":\"#F4D03F\", \n",
    "              \"FAMILY\":\"#faa0eb\", \"RISK_FACTOR\":\"#f8717d\", \"COMPLAINT\":\"#A9DFBF\", \"NEGATION\":\"#9FB1F9\", \"FAMILY_HISTORY_SYNONYM\":\"#BFCC35\",\n",
    "              \"NO_COMPLAINT\":\"#9999CC\", \"NO_SYMPTOM\":\"#D0CFFF\", \"FAMILY_HISTORY\":\"#C6C699\", \"NO_RISK_FACTOR\":\"#FCC6CB\"}\n",
    "    \n",
    "    options = {\"ents\": entities, \"colors\": colors}\n",
    "    \n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALYZE TEXT\n",
    "def analyzeText(text):\n",
    "    \n",
    "    formatedText = re.sub('\\\\.', ' . ', text.lower().strip()) # add space before and after \".\"\n",
    "    formatedText = re.sub(';', ' ; ', formatedText) # add space before and after \";\"\n",
    "    formatedText = re.sub('-', ' - ', formatedText) # add space before and after \"-\"\n",
    "    formatedText = re.sub('\\\\,', ' , ', formatedText) # add space before and after \",\"\n",
    "    formatedText = re.sub(' +', ' ', formatedText) # make text to lowercase and remove multiple spaces\n",
    "\n",
    "    doc = nlp(formatedText)\n",
    "\n",
    "    # change doc tokenization: merge words from one entity\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for ent in doc.ents:\n",
    "            retokenizer.merge(doc[ent.start:ent.end])\n",
    "    \n",
    "    #add mather rules - using lamatization and entities from ruler\n",
    "    from spacy.matcher import Matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # optional adjective + organ\n",
    "    pattern = [[{'POS': 'ADJ',  'OP': '*'},\n",
    "              {'LEMMA': \"и\",  'OP': '*'},\n",
    "              {'POS': 'ADJ',  'OP': '*'},\n",
    "              {'ENT_TYPE': 'ORGAN', 'OP': '+'}]]\n",
    "    matcher.add('ORGAN', pattern)\n",
    "\n",
    "    pattern =[[{'ENT_TYPE':  'ANATOMICAL_SYSTEM', 'OP': '+'}]]\n",
    "    matcher.add('ANATOMICAL_SYSTEM', pattern)\n",
    "    \n",
    "#     pattern =[[{'ENT_TYPE':'FAMILY', 'OP': '+'}]]\n",
    "#     matcher.add('FAMILY', pattern)\n",
    "    \n",
    "    pattern =[[{'ENT_TYPE': 'NEGATION', 'OP': '+'}]]\n",
    "    matcher.add('NEGATION', pattern)\n",
    "    \n",
    "#     pattern =[[{'ENT_TYPE': 'FAMILY_HISTORY_SYNONYM', 'OP': '+'}]]\n",
    "#     matcher.add('FAMILY_HISTORY_SYNONYM', pattern)\n",
    "\n",
    "    pattern =[[{'ENT_TYPE': 'RISK_FACTOR', 'OP': '+'}]]\n",
    "    matcher.add('RISK_FACTOR', pattern)\n",
    "    \n",
    "    pattern =[[{'ENT_TYPE':  'NEGATION', 'OP': '+'},\n",
    "                 {'ENT_TYPE': 'RISK_FACTOR', 'OP': '+'}]]\n",
    "    matcher.add('NO_RISK_FACTOR', pattern)\n",
    "\n",
    "    pattern =[[{'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'}],\n",
    "              [{'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}]\n",
    "             ]\n",
    "    matcher.add('COMPLAINT', pattern)\n",
    "    \n",
    "    pattern =[[{'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}],\n",
    "              [{'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\", 'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'}, \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\", 'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'}, \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}]\n",
    "             ]\n",
    "    matcher.add('SYMPTOM', pattern)\n",
    "    \n",
    "    \n",
    "    pattern =[[{'ENT_TYPE':  'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'}],\n",
    "              [{'ENT_TYPE': 'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'ENT_TYPE': 'NEGATION', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'ENT_TYPE': 'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE':'COMPLAINT', 'OP': '+'}],\n",
    "              [{'ENT_TYPE':'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'}, \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'}, \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'ENT_TYPE':  'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}]\n",
    "             ]\n",
    "    matcher.add('NO_COMPLAINT', pattern)\n",
    "    \n",
    "    pattern =[[{'ENT_TYPE': 'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}],\n",
    "              [{'ENT_TYPE': 'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE':  'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'ENT_TYPE': 'NEGATION', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'ENT_TYPE':  'ORGAN', 'OP': '+'}],\n",
    "              [{'ENT_TYPE':  'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}],\n",
    "              [{'ENT_TYPE': 'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'}, \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'}, \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              [{'ENT_TYPE':  'NEGATION', 'OP': '+'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'POS': 'ADJ',  'OP': '*'},  \n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'COMPLAINT', 'OP': '+'}]\n",
    "             ]\n",
    "    matcher.add('NO_SYMPTOM', pattern)\n",
    "    \n",
    "    pattern =[[{'ENT_TYPE': 'FAMILY', 'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'FAMILY', 'OP': '+'},\n",
    "               {'LEMMA': \"-\",  'OP': '*'},\n",
    "               {'LEMMA': \":\",  'OP': '*'},\n",
    "               {'LEMMA': \"с\",  'OP': '*'},\n",
    "               {'LEMMA': \"със\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}],\n",
    "              \n",
    "              [{'ENT_TYPE': 'FAMILY', 'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'FAMILY', 'OP': '+'},\n",
    "               {'LEMMA': \"-\",  'OP': '*'},\n",
    "               {'LEMMA': \":\",  'OP': '*'},\n",
    "               {'LEMMA': \"с\",  'OP': '*'},\n",
    "               {'LEMMA': \"със\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              \n",
    "              [{'ENT_TYPE': 'FAMILY_HISTORY_SYNONYM', 'OP': '+'},\n",
    "               {'LEMMA': \"за\",  'OP': '*'},\n",
    "               {'LEMMA': \"-\",  'OP': '*'},\n",
    "               {'LEMMA': \":\",  'OP': '*'},\n",
    "               {'ENT_TYPE':  'SYMPTOM', 'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}],\n",
    "              \n",
    "              [{'ENT_TYPE': 'FAMILY_HISTORY_SYNONYM', 'OP': '+'},\n",
    "               {'LEMMA': \"за\",  'OP': '*'},\n",
    "               {'LEMMA': \"-\",  'OP': '*'},\n",
    "               {'LEMMA': \":\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}],\n",
    "              \n",
    "              [{'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'LEMMA': \"-\",  'OP': '*'},\n",
    "               {'LEMMA': \":\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'FAMILY', 'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'FAMILY', 'OP': '+'}],\n",
    "              \n",
    "              [{'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'},\n",
    "               {'LEMMA': \"-\",  'OP': '*'},\n",
    "               {'LEMMA': \":\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'FAMILY', 'OP': '*'},\n",
    "               {'LEMMA': \"и\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'FAMILY', 'OP': '+'}],\n",
    "              \n",
    "              [{'LEMMA': \"обременя-(се)\",  'OP': '+'},\n",
    "               {'LEMMA': \"за\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'}],\n",
    "              \n",
    "              [{'LEMMA': \"обременя-(се)\",  'OP': '+'},\n",
    "               {'LEMMA': \"за\",  'OP': '*'},\n",
    "               {'ENT_TYPE': 'SYMPTOM', 'OP': '+'},\n",
    "               {'POS': 'ADP', 'OP': '+'}, \n",
    "               {'ENT_TYPE': 'ORGAN', 'OP': '+'}]\n",
    "            ]  \n",
    "       \n",
    "    matcher.add('FAMILY_HISTORY', pattern)\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "\n",
    "\n",
    "    spans = []    \n",
    "    doc.ents = [] # clear entities in doc (created from ruler)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        # create a new Span for each match and use the match_id as the label\n",
    "        span = Span(doc, start, end, label=match_id)\n",
    "        if(span[0].text != \"и\"):\n",
    "            spans.append(Span(doc, start, end, label=match_id))\n",
    "    spans = spacy.util.filter_spans(spans); # clear overlaping spans\n",
    "\n",
    "    # add all matching entities to doc.ents\n",
    "    for span in spans:\n",
    "        doc.ents = list(doc.ents) + [span]  # add span to doc.ents\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039917f85d2b4a4ea69d762bac3bdda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<h2>Анализатор на медицински текстове</h2> <h5>Разпознават се обекти…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User interface\n",
    "\n",
    "from ipywidgets import widgets  \n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "DATA_PATH = '..\\\\data\\\\'\n",
    "\n",
    "layout_hidden  = widgets.Layout(visibility = 'hidden')\n",
    "layout_visible = widgets.Layout(visibility = 'visible')\n",
    "\n",
    "def updateDocEnts(tuples):\n",
    "    spans = []    \n",
    "    doc.ents = [] # clear entities in doc (created from ruler)\n",
    "\n",
    "    for text, label, start, end in tuples:\n",
    "        # create a new Span for each match and use the match_id as the label\n",
    "        spans.append(Span(doc, start, end, label))\n",
    "    filteredSpans = spacy.util.filter_spans(spans); # clear overlaping spans\n",
    "\n",
    "    # add all matching entities to doc.ents\n",
    "    for span in filteredSpans:\n",
    "        doc.ents = list(doc.ents) + [span]  # add span to doc.ents\n",
    "        displayResult()\n",
    "\n",
    "def analyzeAndDisplayResult(btn):\n",
    "    global doc\n",
    "    doc = analyzeText(inputBox.value)\n",
    "    displayResult()\n",
    "    spans = [(ent.text, ent.label_, ent.start, ent.end) for ent in doc.ents]\n",
    "\n",
    "    checkResultBox.value = \"\\n\".join(map(str,spans))\n",
    "    checkResultBox.layout = layout_visible\n",
    "    saveButton.layout = layout_visible\n",
    "    applyChangesButton.layout = layout_visible\n",
    "    resultBoxLabel.layout = layout_visible\n",
    "    \n",
    "    \n",
    "def saveToCsv(btn):\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(tuple([ent.start_char, ent.end_char, ent.label_]))\n",
    "    df = pd.DataFrame({'sentense': [doc.text],\n",
    "                   'entities': [entities]})\n",
    "    file = '{0}{1}'.format(DATA_PATH, \"saved_anotations.csv\")\n",
    "    hdr = False  if os.path.isfile(file) else True # if file is new add headers\n",
    "    df.to_csv(file, mode='a', header=hdr, index=False)\n",
    "    \n",
    "\n",
    "\n",
    "def displayResult():\n",
    "    with output:\n",
    "        #clear old output\n",
    "        clear_output(wait=True)\n",
    "        #DISPLAY RESULTS\n",
    "        displacy.render(doc, style='ent', jupyter=True, options=getDisplayOptions())\n",
    "\n",
    "def applyEntitiesChanges(btn):\n",
    "    displayResult()\n",
    "    if validateEntitiesString(checkResultBox.value):\n",
    "        \n",
    "        spans = [(ent.text, ent.label_, ent.start, ent.end) for ent in doc.ents]\n",
    "        userSpans = convert(checkResultBox.value)\n",
    "        \n",
    "        removedSpans =  set(spans) - set(userSpans)\n",
    "        newlySpans = set(userSpans) - set(spans)\n",
    "        \n",
    "        if len(removedSpans) > 0 or len(newlySpans) > 0:\n",
    "            updateDocEnts(userSpans)\n",
    "            \n",
    "\n",
    "    \n",
    "def validateEntitiesString(string):\n",
    "    with output:\n",
    "        r = re.compile(\"\\(\\'.*\\', \\'.*\\', \\d*, \\d*\\)$\")\n",
    "        for token in string.split(\"\\n\"):\n",
    "            if r.match(token) is None:\n",
    "                print('Added entites not match entities pattern')\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "# convert string to list of tuples (used to read changes in entities)    \n",
    "def convert(rawString):\n",
    "    result = []\n",
    "    for entity in rawString.split(\"\\n\"): # every entity is on new line\n",
    "        tupleString = entity.replace(\"(\",\"\").replace(\")\", \"\").replace(\"'\", \"\") #remove (,),'\n",
    "        tupleArray = tupleString.split(\", \");\n",
    "        result.append(tuple([tupleArray[0], tupleArray[1], int(tupleArray[2]), int(tupleArray[3])]))\n",
    "    return result\n",
    "\n",
    "# Create text widget for input\n",
    "inputBox = widgets.Textarea(\n",
    "    placeholder='Напишете текста, който искате да бъде анализиран',\n",
    "    disabled=False)\n",
    "inputBox.layout = layout_visible\n",
    "\n",
    "checkResultBox = widgets.Textarea(\n",
    "    placeholder='Намерени обекти в текста',\n",
    "    continuous_update=False,\n",
    "    disabled=False)\n",
    "checkResultBox.layout = layout_hidden\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "analyzeButton = widgets.Button(description=\"Анализирай\")\n",
    "analyzeButton.layout = layout_visible\n",
    "analyzeButton.on_click(analyzeAndDisplayResult)\n",
    "\n",
    "applyChangesButton = widgets.Button(description=\"Виж промените\")\n",
    "applyChangesButton.layout = layout_hidden\n",
    "applyChangesButton.on_click(applyEntitiesChanges)\n",
    "\n",
    "saveButton = widgets.Button(description=\"Запази\",  tooltip='Текста и обектите се записват във файл data/saved_anotations.csv')\n",
    "saveButton.layout = layout_hidden\n",
    "saveButton.on_click(saveToCsv)\n",
    "\n",
    "resultBoxLabel = widgets.Label(value=\"Резултат от анализа:\")\n",
    "resultBoxLabel.layout = layout_hidden\n",
    "\n",
    "inputLabel = widgets.Label(value=\"Текст за анализиране:\")\n",
    "inputLabel.layout = layout_visible\n",
    "\n",
    "#    print(len(doc)) # number of tokens\n",
    "\n",
    "\n",
    "title = widgets.HTML(\n",
    "    value=\"<h2>Анализатор на медицински текстове</h2> <h5>Разпознават се обекти от следните категории: ORGAN, ANATOMICAL_SYSTEM, SYMPTOM, COMPLAINT, FAMILY, RISK_FACTOR</h5>\"\n",
    ")\n",
    "\n",
    "row0 = widgets.HBox([title])\n",
    "row1 = widgets.HBox([widgets.HBox([widgets.Label(value=\"Текст за анализиране:\")], layout={'width': '150px'}), inputBox, analyzeButton])\n",
    "row2 = widgets.HBox([widgets.HBox([resultBoxLabel], layout={'width': '150px'}), checkResultBox, applyChangesButton])\n",
    "row3 = widgets.HBox([output])\n",
    "row4 = widgets.HBox([saveButton])\n",
    "widgets.VBox((row0, row1, row2, row3, row4))\n",
    "# болки в кръста и гърба, диария, фебрилен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "болки в гърба болки в гърба NOUN root COMPLAINT\n",
      "\n",
      " \n",
      " SPACE  \n",
      "сърце сърце NOUN nmod ORGAN\n",
      "\n",
      " \n",
      " SPACE  \n",
      "фамилна обремененост фамилна обремененост NOUN nmod FAMILY_HISTORY_SYNONYM\n",
      "- - PUNCT punct \n",
      "леля леля NOUN nmod FAMILY_HISTORY\n",
      "с с ADP case FAMILY_HISTORY\n",
      "карцином карцином NOUN nmod FAMILY_HISTORY\n",
      "на на ADP case \n",
      "гърба гърба NOUN nmod \n",
      ", , PUNCT punct \n",
      "брат брат NOUN root FAMILY_HISTORY\n",
      "с с ADP case FAMILY_HISTORY\n",
      "карцином карцином NOUN nmod FAMILY_HISTORY\n",
      "на на ADP case \n",
      "сърцето сърцето NOUN nmod \n",
      ". . PUNCT punct \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
