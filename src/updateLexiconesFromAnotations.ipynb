{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавяне на записаните анотации към лексиконите...\n",
      "болки в кръста и гърба COMPLAINT\n",
      "не пуши NO_RISK_FACTOR\n",
      "баща: починал от рак на белия дроб FAMILY_HISTORY\n",
      "няма NEGATION\n",
      "няма диабет NO_SYMPTOM\n",
      "не пие NO_RISK_FACTOR\n",
      "add\n",
      "рак на белия дроб SYMPTOM\n",
      "add\n",
      "Записаните анотации бяха добавени към лексиконите.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import spacy\n",
    "import stanza\n",
    "from spacy_stanza import StanzaLanguage\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Span\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "DATA_PATH = '..\\\\data\\\\'\n",
    "\n",
    "# #LOAD lexicons\n",
    "lexiconeDic = {\n",
    "    'ORGAN': list(pd.read_csv('{0}{1}'.format(DATA_PATH, \"organs.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'COMPLAINT': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"complaints.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'SYMPTOM': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"symptoms.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'ANATOMICAL_SYSTEM': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"systems.csv\"), sep=',', usecols=['name'], squeeze=True)),\n",
    "    'FAMILY': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"familyRelations.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'RISK_FACTOR': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"riskFactors.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'NEGATION': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"negations.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'FAMILY_HISTORY_SYNONYM': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"familyHistorySynonyms.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "        \n",
    "    'NO_COMPLAINT': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"negationOfComplaints.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'NO_SYMPTOM': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"negationOfSymptoms.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'NO_RISK_FACTOR': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"negationOfRiskFactors.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "    'FAMILY_HISTORY': list(pd.read_csv('{0}{1}'.format(DATA_PATH,\"familyHistory.csv\"), sep='\\n', usecols=['name'], squeeze=True)),\n",
    "}\n",
    "\n",
    "\n",
    "def saveNewAnotationsInHistory():\n",
    "    savedAnotations = pd.read_csv('{0}{1}'.format(DATA_PATH,\"saved_anotations.csv\"), sep=',', squeeze=True)\n",
    "    df = pd.DataFrame(tuple(row) for row in savedAnotations.values)\n",
    "    column_names = [\"sentense\", \"entities\"]\n",
    "    historyAnotations = '{0}{1}'.format(DATA_PATH,\"saved_anotations_history.csv\")\n",
    "    # if file does not exist write header \n",
    "    if not os.path.isfile(historyAnotations):\n",
    "       df.to_csv(historyAnotations, header=column_names, index=False)\n",
    "    else: # else it exists so append without writing the header\n",
    "       df.to_csv(historyAnotations, mode='a', header=False, index=False)\n",
    "\n",
    "def loadNewAnotations():\n",
    "    savedAnotationsPath = '{0}{1}'.format(DATA_PATH,\"saved_anotations.csv\")\n",
    "    savedEntitiesLists = pd.read_csv(savedAnotationsPath, sep=',', usecols=['entities'], squeeze=True)\n",
    "    result = {}\n",
    "    import ast\n",
    "    for row in savedEntitiesLists.values:\n",
    "        listOfTuples = ast.literal_eval(row)\n",
    "        for object in listOfTuples:\n",
    "            result[object[0]] = object[3]\n",
    "    if os.path.exists(savedAnotationsPath):\n",
    "        os.remove(savedAnotationsPath)\n",
    "    return result\n",
    "\n",
    "def getLexiconePathByClass(className):\n",
    "    return {\n",
    "        'ORGAN': '{0}{1}'.format(DATA_PATH, \"organs.csv\"),\n",
    "        'COMPLAINT': '{0}{1}'.format(DATA_PATH,\"complaints.csv\"),\n",
    "        'SYMPTOM': '{0}{1}'.format(DATA_PATH,\"symptoms.csv\"),\n",
    "        'ANATOMICAL_SYSTEM': '{0}{1}'.format(DATA_PATH,\"systems.csv\"),\n",
    "        'FAMILY': '{0}{1}'.format(DATA_PATH,\"familyRelations.csv\"),\n",
    "        'RISK_FACTOR': '{0}{1}'.format(DATA_PATH,\"riskFactors.csv\"),\n",
    "        'NEGATION': '{0}{1}'.format(DATA_PATH,\"negations.csv\"),\n",
    "        'FAMILY_HISTORY_SYNONYM': '{0}{1}'.format(DATA_PATH,\"familyHistorySynonyms.csv\"),\n",
    "        \n",
    "        'NO_COMPLAINT': '{0}{1}'.format(DATA_PATH,\"negationOfComplaints.csv\"),\n",
    "        'NO_SYMPTOM': '{0}{1}'.format(DATA_PATH,\"negationOfSymptoms.csv\"),\n",
    "        'NO_RISK_FACTOR': '{0}{1}'.format(DATA_PATH,\"negationOfRiskFactors.csv\"),\n",
    "        'FAMILY_HISTORY': '{0}{1}'.format(DATA_PATH,\"familyHistory.csv\"),\n",
    "    }[className]\n",
    "\n",
    "def saveObjectToLexicone(object, lexiconeName):\n",
    "    lexiconeDF = pd.DataFrame([object], columns=['name'])\n",
    "    lexiconeDF.to_csv(lexiconeName, mode='a', header=False, index=False)\n",
    "    \n",
    "def removeObjectFromLexicone(object, lexicone):\n",
    "    lexiconePath = getLexiconePathByClass(lexicone)\n",
    "    print(lexiconePath)\n",
    "    df = pd.read_csv(lexiconePath, sep='\\n')\n",
    "    df = df.drop(df.query('name==\"{0}\"'.format(object)).index)\n",
    "    df.shape\n",
    "    df.to_csv(lexiconePath, header=[\"name\"], index=False)\n",
    "    \n",
    "def updateItemInLexicones(object, objectType):\n",
    "    print(object, objectType)\n",
    "    for key, value in lexiconeDic.items():\n",
    "        if object in value and objectType != key:\n",
    "            print(\"remove\")\n",
    "            removeObjectFromLexicone(object, key)\n",
    "        if object not in value and objectType==key:\n",
    "            print(\"add\")\n",
    "            saveObjectToLexicone(object, getLexiconePathByClass(key))\n",
    "    \n",
    "print(\"Добавяне на записаните анотации към лексиконите...\") \n",
    "if os.path.isfile('{0}{1}'.format(DATA_PATH,\"saved_anotations.csv\")):\n",
    "    saveNewAnotationsInHistory()\n",
    "    for key, value in loadNewAnotations().items():\n",
    "        updateItemInLexicones(key, value)\n",
    "print(\"Записаните анотации бяха добавени към лексиконите.\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
